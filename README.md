# Awesome-Multimodel-learning
# 🌐 Awesome Multimodal Learning & Foundation Models

📚 A curated collection of resources related to **Multimodal Learning** and **Multimodal Foundation Models**, including applications in healthcare, vision-language modeling, tutorials, and open-source tools.

---

## 📌 Table of Contents

- [🧠 Tutorials & Workshops](#-tutorials--workshops)
- [🏛 Research Labs](#-research-labs)
- [📊 Applications in Healthcare](#-applications-in-healthcare)
- [🧰 Code & Tools](#-code--tools)
- [📚 Suggested Papers](#-suggested-papers)
- [🤝 Contributing](#-contributing)

---

## 🧠 Tutorials & Workshops

- 🎓 [CVPR 2024 Multimodal LLM Workshop](https://mllm2024.github.io/CVPR2024/)
- 🎓 [ICML 2023 Tutorial on Multimodal Machine Learning](https://cmu-multicomp-lab.github.io/mmml-tutorial/icml2023/)

---

## 🏛 Research Labs

- 🏫 [CMU Multicomp Lab (Homepage)](http://multicomp.cs.cmu.edu/)
- 🔬 [CMU Multicomp Research Projects](http://multicomp.cs.cmu.edu/research/)
- 🧩 [CMU Multimodal Machine Learning Portal](http://multicomp.cs.cmu.edu/multimodal-machine-learning/)
- 💻 [CMU Multicomp GitHub](https://github.com/CMU-MultiComp-Lab)

---

## 📊 Applications in Healthcare

- 🧠 [Google Research – Multimodal Medical AI](https://research.google/blog/multimodal-medical-ai/)
- 🩺 [Owkin: A–Z of AI in Healthcare](https://www.owkin.com/a-z-of-ai-in-healthcare)
- 🔬 [Owkin – Multimodal Data in Healthcare](https://www.owkin.com/a-z-of-ai-for-healthcare/multimodal-data)
- 🔍 [HIT Webinar 谢雨彤 MUZUAI](https://meeting.tencent.com/crm/2qP88r5Rc6)

---

## 🧰 Code & Tools

- 🔗 [CMU MultiComp GitHub](https://github.com/CMU-MultiComp-Lab)
- 🤖 [OpenFlamingo](https://github.com/mlfoundations/open_flamingo)
- 🧠 [LLaVA (Large Language and Vision Assistant)](https://github.com/haotian-liu/LLaVA)
- 📦 [BLIP / BLIP-2 (Salesforce)](https://github.com/salesforce/BLIP)
- 🛠 [HuggingFace Transformers – Multimodal Support](https://huggingface.co/docs/transformers/index)

---

## 📚 Suggested Papers

| Title | Year | Link |
|-------|------|------|
| Multimodal Transformers: A Survey | 2022 | [arXiv](https://arxiv.org/abs/2206.06488) |
| A Survey on Multimodal Learning | 2023 | [arXiv](https://arxiv.org/abs/2304.05499) |
| A Survey on Multimodal Foundation Models | 2023 | [arXiv](https://arxiv.org/abs/2307.12339) |
| Vision-Language Pre-training: A Survey | 2022 | [arXiv](https://arxiv.org/abs/2112.04426) |
| Self-Supervised Multimodal Learning: A Survey | 2021 | [arXiv](https://arxiv.org/abs/2107.08691) |

---

## 🤝 Contributing

Contributions are welcome! If you know of other great multimodal resources, please feel free to open a pull request.

---

## 📄 License

This repository is licensed under the MIT License.
